---
layout:     post   				    # 使用的布局（不需要改）
title:      Evaluation  				# 标题 
subtitle:   Evaluation of algorithm #副标题
date:       2023-06-07 				# 时间
author:     Zhourui 						# 作者
header-img: img/1661857828280-01.jpeg 	#这篇文章标题背景图片
catalog: true 						# 是否归档
tags:								#标签
    - study
---

## study
>Evaluation index of algorithm


1. 精确率与召回率
精确率与召回率多用于二分类问题。精确率（Precision）指的是模型判为正的所有样本中有多少是真正的正样本；召回率（Recall）指的是所有正样本有多少被模型判为正样本，即召回。设模型输出的正样本集合为A，真正的正样本集合为B，则有：

有时候需要在精确率与召回率间进行权衡，一种选择是画出精确率-召回率曲线（Precision-Recall Curve），曲线下的面积被称为AP分数（Average precision score）：

另外一种选择是计算Fβ分数：

当β=1称为F1分数，是分类与信息检索中最常用的指标之一。
2. ROC
设模型输出的正样本集合为A，真正的正样本集合为B，所有样本集合为C，我们称
为真正率（True-positive rate），为假正率（False-positive rate）。
ROC曲线适用于二分类问题，以假正率为横坐标，真正率为纵坐标的曲线图，如：

AUC分数是曲线下的面积（Area under curve），越大意味着分类器效果越好。
3. 对数损失
对数损失（Log loss）亦被称为逻辑回归损失（Logistic regression loss）或交叉熵损失（Cross-entropy loss）。
对于二分类问题，设y∈{0,1}且p=Pr(y=1)，则对每个样本的对数损失为：

将其扩展到多分类问题上。设Y为指示矩阵，即当样本i的分类为k时yi,k=1；设P为估计的概率矩阵，即，则对每个样本的对数损失为：

4. 铰链损失
铰链损失（Hinge loss）一般用来使“边缘最大化”（maximal margin）。
铰链损失最开始出现在二分类问题中，假设正样本被标记为1，负样本被标记为-1，y是真实值，w是预测值，则铰链损失定义为：

然后被扩展到多分类问题，假设yw是对真实分类的预测值，yt是对非真实分类预测中的最大值，则铰链损失定义为：

5. 混淆矩阵
混淆矩阵（Confusion Matrix）又被称为错误矩阵，通过它可以直观地观察到算法的效果。它的每一列是样本的预测分类，每一行是样本的真实分类，它反映了分类结果的混淆程度。混淆矩阵i行j列的原始是原本是类别i却被分为类别j的样本个数，计算完之后还可以对之进行可视化：

6. kappa系数
kappa系数（Cohen’s kappa）用来衡量两种标注结果的吻合程度，标注指的是把N个样本标注为C个互斥类别。计算公式为

其中po是观察到的符合比例，pe是由于随机性产生的符合比例。当两种标注结果完全相符时，K=1，越不相符其值越小，甚至是负的。
是不是云里来雾里去的，现在举个栗子，对于50个测试样本的二分类问题，预测与真实分布情况如下表：
